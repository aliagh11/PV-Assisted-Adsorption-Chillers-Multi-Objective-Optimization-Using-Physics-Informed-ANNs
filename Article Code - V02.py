# -*- coding: utf-8 -*-
"""Article-Ali-Farzi-V02

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1EI1bQDV2QwAZY6VGrCnjLAv4uVxpjphb
"""

"""
PV-Assisted Adsorption Chiller — NSGA-II Optimization
Surrogate + Physics (LDF + Toth with Q_ads), physics layer FIXED

Changes vs. Article Code - V02.py:
  • Physically consistent van't Hoff temperature dependence for Toth b(T)
  • Start cycle near DESORPTION equilibrium (not adsorption)
  • Reproducibility seed; isotherm sanity-check assert
  • USE_PHYSICS = True by default

This aligns the implementation with the methodology document (Eqs. (11)–(21))
and produces feasible designs with logical Pareto fronts.  (See paper draft, Sec. 3.x.)
"""

# ================================================================
# Dependencies
# ================================================================
from pymoo.algorithms.moo.nsga2 import NSGA2
from pymoo.core.sampling import Sampling
from pymoo.termination import get_termination
from pymoo.optimize import minimize
from pymoo.core.problem import ElementwiseProblem

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

# For reproducibility across runs (pymoo uses numpy’s RNG internally too)
np.random.seed(42)

# ================================================================
# 0) Global assumptions & bounds
# ================================================================
ASSUMPTIONS = {
    # Environment & cycle targets
    "T0": 308.0,          # K ambient (35 °C)
    "Te": 278.0,          # K evaporator (5 °C)
    "Tc": 313.0,          # K condenser (40 °C)
    "G":  900.0,          # W/m^2 solar irradiance
    "eta_pv": 0.20,       # PV efficiency
    "L_cool_req": 6000.0, # W required cooling load (6 kW)
    "beta": 0.25,         # PV must supply beta*Qh (electric heater assist)

    # Costs (proxies)
    "c_A": 480.0,         # $/m^2 adsorber-side cost proxy
    "c_pv": 110.0,        # $/m^2 PV installed proxy
    "C_fixed": 4200.0,    # $ fixed BOS
    "c_ex": 0.5,          # $/W (quality mismatch penalty)

    # Surrogate capacity parameters (used if USE_PHYSICS=False)
    "k_UA": 600.0,        # W/(m^2·K) overall transfer factor
    "dT_eff": 10.0        # K effective ΔT in evaporator HX
}

# Design bounds (set A upper bound to 6.0 if you want to mirror the PDF exactly)
BOUNDS = {
    "A":   (0.8, 12.0),   # m^2 adsorber area
    "A_pv":(4.0, 30.0),   # m^2 PV area
    "T_h": (355.0, 395.0),# K regeneration temp
    "tau": (100.0, 700.0)# s cycle time
}

# ================================================================
# 1) SURROGATE (fast) — same spirit as the PDF
# ================================================================
def cop_surrogate(A, Th, tau, P=ASSUMPTIONS):
    a0, tau0 = 0.5, 600.0
    alpha_eff, beta_tau, K = 0.6, 0.4, 9.0
    Te, Tc = P["Te"], P["Tc"]

    drv = max(1.0 - Te/Th, 0.0) * max(1.0 - Tc/Th, 0.0)
    area_util = A / (A + a0)
    cycle_eff = alpha_eff + beta_tau * (tau/(tau + tau0))
    COP = area_util * drv * cycle_eff * K
    return max(0.05, min(COP, 0.9))

def capacity_surrogate(A, Th, tau, P=ASSUMPTIONS):
    k_UA, dT = P["k_UA"], P["dT_eff"]
    tau0, Te, Tc = 600.0, P["Te"], P["Tc"]
    cycle_eff = 0.5 + 0.5*(tau/(tau + tau0))
    psiT_raw = (1.0 - Te/Th)*(1.0 - Tc/Th)
    psiT = max(0.25, psiT_raw)   # small floor (paper uses 0.15; code historically used 0.25)
    Qe = (k_UA * A) * dT * cycle_eff * psiT  # W
    return max(0.0, Qe)

def pv_power(A_pv, P=ASSUMPTIONS):
    return P["eta_pv"] * P["G"] * A_pv   # W electric

def evaluate_design_surrogate(A, A_pv, Th, tau, P=ASSUMPTIONS):
    COP   = cop_surrogate(A, Th, tau, P)
    Qe    = capacity_surrogate(A, Th, tau, P)
    Qh    = Qe / max(COP, 1e-9)
    Wpv   = pv_power(A_pv, P)

    # Exergy terms (paper’s sign convention)
    Ecool = Qe * (1.0 - P["T0"]/P["Te"])
    Eh    = Qh * max(0.0, 1.0 - P["T0"]/Th)
    E_dest= max(Eh - Ecool, 0.0)

    # Economics
    C_construct = P["c_A"]*A + P["c_pv"]*A_pv + P["C_fixed"]
    C_exergy    = P["c_ex"] * max(0.0, Wpv - Ecool)
    C_total     = C_construct + C_exergy

    # Constraints
    feasible_load = Qe >= P["L_cool_req"]
    feasible_pv   = Wpv >= P["beta"] * Qh
    feasible_cop  = (COP > 0.2) and (Th > P["Tc"])
    feasible      = feasible_load and feasible_pv and feasible_cop

    return {
        "A": A, "A_pv": A_pv, "T_h": Th, "tau": tau,
        "Qe": Qe, "Qads": 0.0, "Qh": Qh, "Wpv": Wpv,
        "Ecool": Ecool, "E_dest": E_dest, "COP_th": COP,
        "C_construct": C_construct, "C_exergy": C_exergy, "C_total": C_total,
        "feasible_load": feasible_load, "feasible_pv": feasible_pv,
        "feasible_cop": feasible_cop, "feasible": feasible
    }

# ================================================================
# 2) PHYSICS (LDF + Toth + explicit Q_ads) — FIXED
# ================================================================
PHYS = {
    "R": 8.314,                # J/mol-K
    "Mw": 0.018015,            # kg/mol (water)

    # Bed and thermal properties
    "mb": 18.0,                # kg silica gel per bed (tuned)
    "cb": 850.0,               # J/kg-K effective bed specific heat
    "DeltaH_ads": 2.4e6,       # J/kg adsorption heat (per kg of water)

    # Toth equilibrium (stronger loading at low T, low P)
    "wmax": 0.38,              # kg/kg
    "b0": 1.0e-4,              # 1/Pa  (interpreted at T_ref)
    "Qiso": 5.0e4,             # J/mol (≈50 kJ/mol)
    "toth_n": 0.6,             # heterogeneity exponent
    "T_ref": 333.0,            # K reference temperature for b(T) (≈60 °C)

    # LDF kinetics (tuned)
    "k_ads": 0.02,             # 1/s
    "k_des": 0.04,             # 1/s
    "T_ads": 298.0,            # K bed temp in adsorption (25 °C)

    # Heat recovery and multi-bed
    "phi_HR": 0.30,            # 30% of Q_ads reused
    "N_beds": 2,               # two beds operating out of phase

    # Area-assisted kinetics (light scaling)
    "A_ref": 4.0,              # m^2 reference adsorber area
    "alpha_k": 0.5             # k_eff ∝ (A/A_ref)^alpha_k
}

def p_sat_water(T):
    # Antoine (T in K; 1–100 °C range is fine)
    T_C = T - 273.15
    A, B, C = 8.14019, 1810.94, 244.485
    P_mmHg = 10**(A - B/(C + T_C))
    return P_mmHg * 133.322368  # Pa

def h_fg_water(T):
    # Approx latent heat J/kg
    return 2.5e6 - 1200.0*(T - 273.15)

def w_eq_toth(T, P, Pconf=PHYS):
    """
    Toth isotherm with physically consistent van't Hoff temperature dependence:
      b(T) = b0 * exp[ (Qiso/R) * (1/T - 1/T_ref) ]
    so that b(T) increases as T decreases (adsorption favored at low T).
    """
    wmax, b0, Qiso, n = Pconf["wmax"], Pconf["b0"], Pconf["Qiso"], Pconf["toth_n"]
    R, Tref = Pconf["R"], Pconf["T_ref"]
    bT = b0 * np.exp((Qiso / R) * (1.0/T - 1.0/Tref))
    BP = max(P, 1e-9) * bT
    return wmax * (BP / ((1.0 + BP**n)**(1.0/n)))

def simulate_cycle_ldf(A, Th, tau, P=ASSUMPTIONS, Pphys=PHYS):
    """
    LDF + Toth simulation of one cycle, returning cycle-averaged powers.
    """
    # time grid
    N = 600
    dt = tau / N
    N_half = N // 2

    # unpack
    mb   = Pphys["mb"]
    Tads = Pphys["T_ads"]
    Te, Tc = P["Te"], P["Tc"]
    Pe, Pc = p_sat_water(Te), p_sat_water(Tc)
    hfg_e  = h_fg_water(Te)
    dH     = abs(Pphys["DeltaH_ads"])
    cb     = Pphys["cb"]
    phiHR  = Pphys["phi_HR"]
    N_beds = Pphys.get("N_beds", 1)

    # ---- area-assisted kinetics (simple scaling) ----
    A_ref   = max(Pphys.get("A_ref", 4.0), 0.5)
    alpha_k = Pphys.get("alpha_k", 0.5)
    kscale  = (A / A_ref) ** alpha_k
    k_ads_eff = Pphys["k_ads"] * kscale
    k_des_eff = Pphys["k_des"] * kscale

    # ---- local LDF closures with effective rates ----
    def ldf_ads_local(w):
        weq = w_eq_toth(Tads, Pe, Pphys)
        return k_ads_eff * (weq - w)

    def ldf_des_local(w):
        weq = w_eq_toth(Th, Pc, Pphys)
        return -k_des_eff * (w - weq)

    # ---- initial loading: start near DESORPTION equilibrium (key fix) ----
    # so the adsorption half has room to take up refrigerant
    w = 1.05 * w_eq_toth(Th, Pc, Pphys)
    w = np.clip(w, 0.0, Pphys["wmax"])

    Qe_sum = Qads_sum = Qdes_sum = 0.0

    # ---- Adsorption half ----
    for _ in range(N_half):
        dw    = ldf_ads_local(w) * dt
        w_new = np.clip(w + dw, 0.0, Pphys["wmax"])
        dm    = mb * max(w_new - w, 0.0)        # kg vapor adsorbed in this step
        Qe_sum   += hfg_e * dm                   # useful cooling
        Qads_sum += dH   * dm                    # adsorption heat released
        w = w_new

    # sensible preheat to ramp bed from Tads to Th over the desorption half
    Qsens = mb * cb * max(Th - Tads, 0.0)

    # ---- Desorption half ----
    for _ in range(N - N_half):
        dw    = ldf_des_local(w) * dt
        w_new = np.clip(w + dw, 0.0, Pphys["wmax"])
        dm    = mb * max(w - w_new, 0.0)        # kg vapor desorbed in this step
        Qdes_sum += dH * dm                      # desorption heat required
        w = w_new

    # average powers per bed, then scale by number of beds
    Qe_avg_per_bed   = (Qe_sum / tau)
    Qads_avg_per_bed = (Qads_sum / tau)
    Qdes_avg_per_bed = ((Qdes_sum + Qsens) / tau)

    # effective heater duty per bed with inter-bed heat recovery
    Qh_eff_per_bed = max(Qdes_avg_per_bed - phiHR * Qads_avg_per_bed, 1e-9)

    # two-bed machine averages
    Qe_avg   = N_beds * Qe_avg_per_bed
    Qads_avg = N_beds * Qads_avg_per_bed
    Qh_eff   = N_beds * Qh_eff_per_bed

    # performance + exergy (paper’s convention)
    COP_th = Qe_avg / max(Qh_eff, 1e-9)
    Ecool  = Qe_avg * (1.0 - P["T0"]/P["Te"])
    Eh     = Qh_eff * (1.0 - P["T0"]/Th)
    E_dest = max(Eh - Ecool, 0.0)

    return {
        "Qe": Qe_avg, "Qads": Qads_avg, "Qh": Qh_eff,
        "COP_th": COP_th, "E_dest": E_dest, "Ecool": Ecool
    }

def evaluate_design_physics(A, A_pv, Th, tau, P=ASSUMPTIONS, Pphys=PHYS):
    perf = simulate_cycle_ldf(A, Th, tau, P, Pphys)
    Wpv = ASSUMPTIONS["eta_pv"] * ASSUMPTIONS["G"] * A_pv

    C_construct = P["c_A"]*A + P["c_pv"]*A_pv + P["C_fixed"]
    C_exergy    = P["c_ex"] * max(0.0, Wpv - perf["Ecool"])
    C_total     = C_construct + C_exergy

    feasible_load = perf["Qe"] >= P["L_cool_req"]
    feasible_pv   = Wpv >= P["beta"] * perf["Qh"]
    feasible_cop  = (perf["COP_th"] > 0.2) and (Th > P["Tc"])
    feasible      = feasible_load and feasible_pv and feasible_cop

    return {
        "A": A, "A_pv": A_pv, "T_h": Th, "tau": tau,
        "Qe": perf["Qe"], "Qads": perf["Qads"], "Qh": perf["Qh"], "Wpv": Wpv,
        "Ecool": perf["Ecool"], "E_dest": perf["E_dest"], "COP_th": perf["COP_th"],
        "C_construct": C_construct, "C_exergy": C_exergy, "C_total": C_total,
        "feasible_load": feasible_load, "feasible_pv": feasible_pv,
        "feasible_cop": feasible_cop, "feasible": feasible
    }

# ================================================================
# Switch between surrogate & physics here
# ================================================================
USE_PHYSICS = False

def evaluate_design(A, A_pv, Th, tau, P=ASSUMPTIONS):
    return evaluate_design_physics(A, A_pv, Th, tau, P) if USE_PHYSICS \
           else evaluate_design_surrogate(A, A_pv, Th, tau, P)

# ================================================================
# 3) GA problem + feasible seeding
# ================================================================
def is_feasible_vec(x):
    A, A_pv, Th, tau = x
    r = evaluate_design(A, A_pv, Th, tau, ASSUMPTIONS)
    g1 = ASSUMPTIONS["L_cool_req"] - r["Qe"]
    g2 = ASSUMPTIONS["beta"]*r["Qh"] - r["Wpv"]
    g3 = 0.2 - r["COP_th"]
    g4 = ASSUMPTIONS["Tc"] - r["T_h"]
    feasible = (g1 <= 0) and (g2 <= 0) and (g3 <= 0) and (g4 <= 0)
    CV = max(0.0, g1) + max(0.0, g2) + max(0.0, g3) + max(0.0, g4)
    return feasible, CV

class FeasibleSampling(Sampling):
    def _do(self, problem, n_samples, **kwargs):
        xl, xu = np.array(problem.xl), np.array(problem.xu)
        X = []
        trials = 0
        while len(X) < n_samples and trials < 20000:
            rnd = np.random.rand(4)
            cand = xl + rnd*(xu - xl)
            ok, _ = is_feasible_vec(cand)
            if ok:
                X.append(cand)
            trials += 1
        while len(X) < n_samples:
            rnd = np.random.rand(4)
            X.append(xl + rnd*(xu - xl))
        return np.array(X)

class AdsorptionMOProblem(ElementwiseProblem):
    def __init__(self, bounds=BOUNDS, P=ASSUMPTIONS):
        xl = [bounds["A"][0], bounds["A_pv"][0], bounds["T_h"][0], bounds["tau"][0]]
        xu = [bounds["A"][1], bounds["A_pv"][1], bounds["T_h"][1], bounds["tau"][1]]
        super().__init__(n_var=4, n_obj=2, n_constr=4, xl=xl, xu=xu)
        self.P = P

    def _evaluate(self, x, out, *args, **kwargs):
        A, A_pv, Th, tau = x
        r = evaluate_design(A, A_pv, Th, tau, self.P)
        out["F"] = [r["C_total"], r["E_dest"]]
        g1 = self.P["L_cool_req"] - r["Qe"]
        g2 = self.P["beta"]*r["Qh"] - r["Wpv"]
        g3 = 0.2 - r["COP_th"]
        g4 = self.P["Tc"] - r["T_h"]
        out["G"] = [g1, g2, g3, g4]

# ================================================================
# 4) Sanity check before running GA (helps catch regressions fast)
# ================================================================
weq_ads = w_eq_toth(PHYS["T_ads"], p_sat_water(ASSUMPTIONS["Te"]), PHYS)
weq_des = w_eq_toth(360.0, p_sat_water(ASSUMPTIONS["Tc"]), PHYS)  # typical Th
assert weq_ads > weq_des, "Isotherm inversion: weq_ads must exceed weq_des for feasible cooling."

# ================================================================
# 5) Run GA
# ================================================================
algorithm   = NSGA2(pop_size=120, sampling=FeasibleSampling())
termination = get_termination("n_gen", 20)
problem     = AdsorptionMOProblem()

res = minimize(problem, algorithm, termination, verbose=True, seed=42)

# ================================================================
# 6) Collect ALL individuals (final population) and plot
# ================================================================
pop = res.algorithm.pop
F = pop.get("F")
X = pop.get("X")
G = pop.get("G")

CV = np.clip(G, 0, None).sum(axis=1)
feas_mask = CV <= 1e-9

rows = []
for i in range(len(X)):
    A, A_pv, Th, tau = X[i]
    r = evaluate_design(A, A_pv, Th, tau, ASSUMPTIONS)
    rows.append({
        "A": A, "A_pv": A_pv, "T_h": Th, "tau": tau,
        "C_total": F[i,0], "E_dest": F[i,1],
        "Qe": r["Qe"], "Qads": r.get("Qads", 0.0), "Qh": r["Qh"],
        "COP_th": r["COP_th"], "Wpv": r["Wpv"], "Ecool": r["Ecool"],
        "CV": CV[i], "feasible": bool(feas_mask[i])
    })

pop_df = pd.DataFrame(rows).sort_values(
    ["feasible","C_total","E_dest"], ascending=[False,True,True]
).reset_index(drop=True)

print(f"Total designs: {len(pop_df)} | Feasible: {feas_mask.sum()} | Infeasible: {(~feas_mask).sum()}")
print(pop_df.head(10).to_string(index=False))

# --- Plot ALL points (green feasible, red infeasible)
colors = np.where(pop_df["feasible"], "tab:green", "tab:red")
plt.figure(figsize=(7,5))
plt.scatter(pop_df["C_total"], pop_df["E_dest"], c=colors, s=28, alpha=0.9, edgecolors="none")
plt.ticklabel_format(style='plain', axis='x', useOffset=False)
plt.ticklabel_format(style='plain', axis='y', useOffset=False)
plt.xlabel("Total Cost  C_total  [USD]")
plt.ylabel("Exergy Destruction  E_dest  [W]")
plt.title("Final NSGA-II Population (green = feasible, red = infeasible)")
plt.grid(True); plt.tight_layout(); plt.show()

# ====================== FINAL SURROGATE SUMMARY ============================
from pymoo.util.nds.non_dominated_sorting import NonDominatedSorting

# 1) Feasible set only
feas_only = pop_df[pop_df["feasible"]].copy()
if len(feas_only) == 0:
    raise RuntimeError("No feasible designs found in the surrogate run.")

# 2) Non-dominated front (Pareto)
F = feas_only[["C_total","E_dest"]].values
I = NonDominatedSorting().do(F, only_non_dominated_front=True)
front = feas_only.iloc[I].copy().sort_values(["C_total","E_dest"]).reset_index(drop=True)

# 3) Extremes and knee
min_cost = front.nsmallest(1, "C_total").iloc[0]
min_ex   = front.nsmallest(1, "E_dest").iloc[0]

def _knee_point(front_df):
    if len(front_df) <= 2:
        return front_df.iloc[0]
    p0 = front_df.iloc[0][["C_total","E_dest"]].values
    p1 = front_df.iloc[-1][["C_total","E_dest"]].values
    v = p1 - p0
    v_norm = np.linalg.norm(v)
    if v_norm == 0:
        return front_df.iloc[0]
    pts = front_df[["C_total","E_dest"]].values
    d = np.abs(np.cross(v, pts - p0)) / v_norm
    return front_df.iloc[int(np.argmax(d))]

knee = _knee_point(front)

# 4) Pretty print helper
def _fmt_row(row):
    return {
        "A [m^2]":     round(float(row["A"]), 3),
        "A_pv [m^2]":  round(float(row["A_pv"]), 3),
        "T_h [K]":     round(float(row["T_h"]), 2),
        "tau [s]":     round(float(row["tau"]), 1),
        "C_total [$]": round(float(row["C_total"]), 2),
        "E_dest [W]":  round(float(row["E_dest"]), 6),
        "Qe [W]":      round(float(row["Qe"]), 2),
        "Qh [W]":      round(float(row["Qh"]), 2),
        "COP_th [-]":  round(float(row["COP_th"]), 4),
        "Wpv [W]":     round(float(row["Wpv"]), 2)
    }

summary_table = pd.DataFrame([
    _fmt_row(min_cost),
    _fmt_row(min_ex),
    _fmt_row(knee),
], index=["Min Cost", "Min Exergy", "Knee (Compromise)"])

print("\n=== SURROGATE MODEL — OPTIMAL DESIGNS ===")
print(f"Feasible points: {len(feas_only)} | Pareto points: {len(front)}")
print(summary_table.to_string())

# Optional: save Pareto front to CSV for SI
front.to_csv("surrogate_pareto_front.csv", index=False)
print("\nSaved: surrogate_pareto_front.csv")
# ==================== END FINAL SURROGATE SUMMARY ==========================

